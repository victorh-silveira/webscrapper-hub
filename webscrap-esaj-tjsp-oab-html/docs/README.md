# WebScrapGabriel

Este projeto realiza **web scraping** para extrair dados de processos judiciais e converte os arquivos **JSON** resultantes para **XLSX**.

---

## ğŸ“Œ Ãndice
- [DescriÃ§Ã£o](#descriÃ§Ã£o)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [PrÃ©-requisitos](#prÃ©-requisitos)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [ExecuÃ§Ã£o](#execuÃ§Ã£o)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Docker](#docker)
- [LicenÃ§a](#licenÃ§a)

---

## ğŸ“Œ DescriÃ§Ã£o

O projeto acessa um site jurÃ­dico, coleta dados sobre processos e armazena os resultados no formato **JSON**. Em seguida, converte os arquivos JSON em planilhas **XLSX** para melhor visualizaÃ§Ã£o e anÃ¡lise dos dados.

---

## ğŸ“Œ Tecnologias Utilizadas

- **Python 3.10**
- **BeautifulSoup4** (para scraping de HTML)
- **Requests** (para requisiÃ§Ãµes HTTP)
- **Pandas** (para manipulaÃ§Ã£o de dados)
- **OpenPyXL** (para conversÃ£o de JSON para XLSX)
- **Docker** (opcional para ambiente isolado)

---

## ğŸ“Œ PrÃ©-requisitos

Antes de rodar o projeto, certifique-se de ter instalado:

- **Python 3.10+**
- **Pip** (gerenciador de pacotes do Python)
- **Docker** (caso queira rodar o projeto em container)

---

## ğŸ“Œ InstalaÃ§Ã£o

### **1. Clone o repositÃ³rio**
```sh
git clone https://github.com/seu-usuario/WebScrapGabriel.git
cd WebScrapGabriel
2. Crie um ambiente virtual (opcional, mas recomendado)
sh
Copiar
Editar
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows
3. Instale as dependÃªncias
sh
Copiar
Editar
pip install -r docs/requirements.txt
ğŸ“Œ ExecuÃ§Ã£o
Executando diretamente no Python
ApÃ³s instalar as dependÃªncias, basta rodar:

sh
Copiar
Editar
python main.py
O programa farÃ¡:

Web scraping e salvarÃ¡ os dados JSON em data/json/.
ConversÃ£o automÃ¡tica dos JSONs para XLSX em data/xlsx/.
ğŸ“Œ Estrutura do Projeto
graphql
Copiar
Editar
ğŸ“¦ WebScrapGabriel
 â”£ ğŸ“‚ data               # Armazena os arquivos de saÃ­da
 â”ƒ â”£ ğŸ“‚ json             # Arquivos JSON gerados pelo scraper
 â”ƒ â”£ ğŸ“‚ xlsx             # Arquivos XLSX convertidos do JSON
 â”£ ğŸ“‚ docs               # DocumentaÃ§Ã£o e dependÃªncias
 â”£ ğŸ“‚ logs               # Logs de execuÃ§Ã£o e erros
 â”£ ğŸ“‚ scripts            # Scripts principais do projeto
 â”ƒ â”£ ğŸ webScraper.py    # CÃ³digo de scraping
 â”ƒ â”£ ğŸ jsonToXlsx.py    # ConversÃ£o de JSON para XLSX
 â”ƒ â”£ ğŸ config.py        # ConfiguraÃ§Ãµes globais
 â”£ ğŸ main.py            # Arquivo principal para rodar o pipeline
 â”£ ğŸ³ Dockerfile         # Arquivo para rodar o projeto via Docker
 â”£ ğŸ“„ README.md          # DocumentaÃ§Ã£o do projeto
 â”£ ğŸ“„ .gitignore         # Ignora arquivos desnecessÃ¡rios no Git
ğŸ“Œ Docker
Caso queira rodar o projeto via Docker, siga os passos:

1. Construir a imagem
sh
Copiar
Editar
docker build -t webscrapgabriel .
2. Rodar o container
sh
Copiar
Editar
docker run --rm -v "$(pwd)/data:/app/data" webscrapgabriel
Isso executarÃ¡ o scraper e salvarÃ¡ os arquivos JSON e XLSX na pasta data/.

ğŸ“Œ LicenÃ§a
Este projeto estÃ¡ sob a LicenÃ§a MIT. VocÃª pode usÃ¡-lo e modificÃ¡-lo livremente.

ğŸ“Œ Como subir para o GitHub
Copie este conteÃºdo e cole no seu arquivo README.md no VSCode.
Salve o arquivo e envie para o GitHub com os comandos abaixo:
sh
Copiar
Editar
git add README.md
git commit -m "Adicionando README.md formatado"
git push origin main
Agora o README.md estÃ¡ corretamente formatado e pronto para ser publicado no GitHub.

yaml
Copiar
Editar

---

### **ğŸ“Œ O que foi corrigido?**
âœ… **Corrigido formataÃ§Ã£o errada em comandos de terminal.**  
âœ… **Removidos trechos duplicados e mal formatados.**  
âœ… **Melhorado layout da estrutura do projeto.**  
âœ… **Agora o README pode ser copiado e colado diretamente no VSCode.**  

Agora Ã© sÃ³ copiar, colar no **VSCode** e subir para o **GitHub**!
